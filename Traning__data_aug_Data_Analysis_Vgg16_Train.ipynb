{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vishnuvsgthn/Classification/blob/main/Traning__data_aug_Data_Analysis_Vgg16_Train.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GDug5w7YwtqL",
        "outputId": "a1d4665b-7755-4fa9-f402-b5d5cfd68c85"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/Crayon\n"
          ]
        }
      ],
      "source": [
        "%cd drive/MyDrive/Crayon"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7newXD-fz5L2",
        "outputId": "200c1bc2-2ffb-4cef-e677-d8d405010d1e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ODw1yw4l2S-g",
        "outputId": "c1a63660-d064-4cc6-da06-3ac539a7cc19"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of images in traning covid p folder\n",
            "735\n",
            "Number of images in traning covid_n folder\n",
            "1540\n",
            "Number of images in validation covid p folder\n",
            "15\n",
            "Number of images in validation covid_n folder\n",
            "30\n",
            "Number of images in test covid p folder\n",
            "30\n",
            "Number of images in test covid_n folder\n",
            "60\n"
          ]
        }
      ],
      "source": [
        "#Finding the number of images for train test and validation\n",
        "print(\"Number of images in traning covid p folder\")\n",
        "!ls ./temp/Train_Augment/Augment/covid_p/ | wc -l\n",
        "print(\"Number of images in traning covid_n folder\")\n",
        "!ls ./temp/Train_Augment/Augment/covid_n/ | wc -l\n",
        "\n",
        "print(\"Number of images in validation covid p folder\")\n",
        "!ls ./temp/Validation/covid_p/ | wc -l\n",
        "print(\"Number of images in validation covid_n folder\")\n",
        "!ls ./temp/Validation/covid_n/ | wc -l\n",
        "\n",
        "print(\"Number of images in test covid p folder\")\n",
        "!ls ./temp/Test/covid_p/ | wc -l\n",
        "print(\"Number of images in test covid_n folder\")\n",
        "!ls ./temp/Test/covid_n/ | wc -l\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "hOskcXbu3dMM"
      },
      "outputs": [],
      "source": [
        "import sklearn\n",
        "import os \n",
        "import zipfile \n",
        "import tensorflow as tf \n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator \n",
        "from tensorflow.keras import layers \n",
        "from tensorflow.keras import Model \n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Jf8R9Z_F34Y8"
      },
      "outputs": [],
      "source": [
        "# local_zip = './Dataset/dataset.zip'\n",
        "# zip_ref = zipfile.ZipFile(local_zip, 'r')\n",
        "# zip_ref.extractall('./temp')\n",
        "# zip_ref.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "ZMdLN6Sf3_oz"
      },
      "outputs": [],
      "source": [
        "base_dir = './temp'\n",
        "base_dir_train = './temp/Train_Augment'\n",
        "train_dir = os.path.join(base_dir_train, 'Augment')\n",
        "validation_dir = os.path.join(base_dir, 'Validation')\n",
        "\n",
        "# Directory with our training cat pictures\n",
        "train_cneg_dir = os.path.join(train_dir, 'covid_n')\n",
        "\n",
        "# Directory with our training dog pictures\n",
        "train_cpos_dir = os.path.join(train_dir, 'covid_p')\n",
        "\n",
        "# Directory with our validation cat pictures\n",
        "validation_cneg_dir = os.path.join(validation_dir, 'covid_n')\n",
        "\n",
        "# Directory with our validation dog pictures\n",
        "validation_pos_dir = os.path.join(validation_dir, 'covid_p')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "a7tNAAjv9nAz"
      },
      "outputs": [],
      "source": [
        "# Add our data-augmentation parameters to ImageDataGenerator\n",
        "train_datagen = ImageDataGenerator(rescale = 1./255., rotation_range = 7, width_shift_range = 0.2, height_shift_range = 0.2,shear_range = 0.2, zoom_range = 0.2, horizontal_flip = True,brightness_range=[0.4,1.5])\n",
        "\n",
        "test_datagen = ImageDataGenerator( rescale = 1.0/255. )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AsP9J3pW90zV",
        "outputId": "7d244906-1a29-40ea-8d38-769beb88e94a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 2275 images belonging to 2 classes.\n",
            "Found 45 images belonging to 2 classes.\n"
          ]
        }
      ],
      "source": [
        "train_generator = train_datagen.flow_from_directory(train_dir, batch_size = 16, class_mode = 'binary', target_size = (224, 224))\n",
        "validation_generator = test_datagen.flow_from_directory(validation_dir, batch_size = 8, class_mode = 'binary', target_size = (224, 224))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "irEt_hnM-FHD"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "class_weights = compute_class_weight(class_weight = \"balanced\", classes= np.unique(train_generator.classes), y= train_generator.classes)\n",
        "#class_weights = dict((np.unique(train_generator.classes), class_weights)),\n",
        "#class_weights =  class_weights[0]\n",
        "class_weights = {0: class_weights[0], 1:class_weights[1]}\n",
        "#class_ids = list(sorted(class_weights.keys()))\n",
        "#class_ids\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "mu2dA7Tc-xLB"
      },
      "outputs": [],
      "source": [
        "#addign vgg16\n",
        "from tensorflow.keras.applications import VGG16\n",
        "\n",
        "base_model = VGG16(input_shape=(224, 224,3), include_top=False, weights=\"imagenet\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "3IVxtAw__QGp"
      },
      "outputs": [],
      "source": [
        "for layer in base_model.layers:\n",
        "    layer.trainable = True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "tO6Ri7C-_mxP"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.applications import VGG16\n",
        "from tensorflow.python.keras.models import Sequential\n",
        "from tensorflow.python.keras.layers import Dense, Flatten, GlobalAveragePooling2D\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "base_model = Sequential()\n",
        "base_model.add(VGG16(include_top=False, weights='imagenet', pooling='max'))\n",
        "base_model.add(Dense(1, activation='sigmoid'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "uH6BUGVI_wXZ"
      },
      "outputs": [],
      "source": [
        "save_path ='./content/drive/MyDrive/Crayon/Models/VGG16'\n",
        "checkpoint = ModelCheckpoint(save_path, verbose=1, monitor='val_loss',save_best_only=True, mode='auto')  \n",
        "optimizer = Adam(learning_rate=0.0001)\n",
        "base_model.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['acc'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XzqmvFpSAQQh",
        "outputId": "f7104bab-7eaa-4dd8-e56a-25d0af89cf46"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "Epoch 1/25\n",
            "142/142 [==============================] - 563s 4s/step - loss: 0.7383 - acc: 0.5229 - val_loss: 0.5220 - val_acc: 0.6750\n",
            "\n",
            "Epoch 1: val_loss improved from inf to 0.52203, saving model to ./content/drive/MyDrive/Crayon/Models/VGG16\n",
            "INFO:tensorflow:Assets written to: ./content/drive/MyDrive/Crayon/Models/VGG16/assets\n",
            "Epoch 2/25\n",
            "142/142 [==============================] - 63s 435ms/step - loss: 0.5574 - acc: 0.7353 - val_loss: 0.4810 - val_acc: 0.8000\n",
            "\n",
            "Epoch 2: val_loss improved from 0.52203 to 0.48101, saving model to ./content/drive/MyDrive/Crayon/Models/VGG16\n",
            "INFO:tensorflow:Assets written to: ./content/drive/MyDrive/Crayon/Models/VGG16/assets\n",
            "Epoch 3/25\n",
            "142/142 [==============================] - 62s 436ms/step - loss: 0.5241 - acc: 0.7627 - val_loss: 0.4478 - val_acc: 0.8250\n",
            "\n",
            "Epoch 3: val_loss improved from 0.48101 to 0.44784, saving model to ./content/drive/MyDrive/Crayon/Models/VGG16\n",
            "INFO:tensorflow:Assets written to: ./content/drive/MyDrive/Crayon/Models/VGG16/assets\n",
            "Epoch 4/25\n",
            "142/142 [==============================] - 62s 440ms/step - loss: 0.4960 - acc: 0.7725 - val_loss: 0.4310 - val_acc: 0.8000\n",
            "\n",
            "Epoch 4: val_loss improved from 0.44784 to 0.43100, saving model to ./content/drive/MyDrive/Crayon/Models/VGG16\n",
            "INFO:tensorflow:Assets written to: ./content/drive/MyDrive/Crayon/Models/VGG16/assets\n",
            "Epoch 5/25\n",
            "142/142 [==============================] - 62s 435ms/step - loss: 0.4816 - acc: 0.7844 - val_loss: 0.3526 - val_acc: 0.8500\n",
            "\n",
            "Epoch 5: val_loss improved from 0.43100 to 0.35256, saving model to ./content/drive/MyDrive/Crayon/Models/VGG16\n",
            "INFO:tensorflow:Assets written to: ./content/drive/MyDrive/Crayon/Models/VGG16/assets\n",
            "Epoch 6/25\n",
            "142/142 [==============================] - 62s 436ms/step - loss: 0.4456 - acc: 0.8043 - val_loss: 0.5164 - val_acc: 0.8500\n",
            "\n",
            "Epoch 6: val_loss did not improve from 0.35256\n",
            "Epoch 7/25\n",
            "142/142 [==============================] - 62s 439ms/step - loss: 0.3681 - acc: 0.8406 - val_loss: 0.3804 - val_acc: 0.8500\n",
            "\n",
            "Epoch 7: val_loss did not improve from 0.35256\n",
            "Epoch 8/25\n",
            "142/142 [==============================] - 62s 437ms/step - loss: 0.5614 - acc: 0.7193 - val_loss: 0.5924 - val_acc: 0.7000\n",
            "\n",
            "Epoch 8: val_loss did not improve from 0.35256\n",
            "Epoch 9/25\n",
            "142/142 [==============================] - 63s 442ms/step - loss: 0.4631 - acc: 0.8052 - val_loss: 0.3900 - val_acc: 0.7500\n",
            "\n",
            "Epoch 9: val_loss did not improve from 0.35256\n",
            "Epoch 10/25\n",
            "142/142 [==============================] - 62s 441ms/step - loss: 0.3748 - acc: 0.8468 - val_loss: 0.4302 - val_acc: 0.8250\n",
            "\n",
            "Epoch 10: val_loss did not improve from 0.35256\n",
            "Epoch 11/25\n",
            "142/142 [==============================] - 62s 440ms/step - loss: 0.4372 - acc: 0.8216 - val_loss: 0.2483 - val_acc: 0.8500\n",
            "\n",
            "Epoch 11: val_loss improved from 0.35256 to 0.24827, saving model to ./content/drive/MyDrive/Crayon/Models/VGG16\n",
            "INFO:tensorflow:Assets written to: ./content/drive/MyDrive/Crayon/Models/VGG16/assets\n",
            "Epoch 12/25\n",
            "142/142 [==============================] - 62s 435ms/step - loss: 0.3747 - acc: 0.8371 - val_loss: 0.3159 - val_acc: 0.8250\n",
            "\n",
            "Epoch 12: val_loss did not improve from 0.24827\n",
            "Epoch 13/25\n",
            "142/142 [==============================] - 62s 437ms/step - loss: 0.2791 - acc: 0.8920 - val_loss: 0.4244 - val_acc: 0.7750\n",
            "\n",
            "Epoch 13: val_loss did not improve from 0.24827\n",
            "Epoch 14/25\n",
            "142/142 [==============================] - 62s 441ms/step - loss: 0.2940 - acc: 0.8787 - val_loss: 0.3469 - val_acc: 0.8500\n",
            "\n",
            "Epoch 14: val_loss did not improve from 0.24827\n",
            "Epoch 15/25\n",
            "142/142 [==============================] - 62s 439ms/step - loss: 0.2932 - acc: 0.8796 - val_loss: 0.4409 - val_acc: 0.7250\n",
            "\n",
            "Epoch 15: val_loss did not improve from 0.24827\n",
            "Epoch 16/25\n",
            "142/142 [==============================] - 62s 436ms/step - loss: 0.2856 - acc: 0.8783 - val_loss: 0.2909 - val_acc: 0.8000\n",
            "\n",
            "Epoch 16: val_loss did not improve from 0.24827\n",
            "Epoch 17/25\n",
            "142/142 [==============================] - 62s 440ms/step - loss: 0.2717 - acc: 0.8951 - val_loss: 0.3020 - val_acc: 0.8750\n",
            "\n",
            "Epoch 17: val_loss did not improve from 0.24827\n",
            "Epoch 18/25\n",
            "142/142 [==============================] - 62s 438ms/step - loss: 0.2341 - acc: 0.9048 - val_loss: 0.2678 - val_acc: 0.8500\n",
            "\n",
            "Epoch 18: val_loss did not improve from 0.24827\n",
            "Epoch 19/25\n",
            "142/142 [==============================] - 63s 445ms/step - loss: 0.2160 - acc: 0.9132 - val_loss: 0.2052 - val_acc: 0.8750\n",
            "\n",
            "Epoch 19: val_loss improved from 0.24827 to 0.20516, saving model to ./content/drive/MyDrive/Crayon/Models/VGG16\n",
            "INFO:tensorflow:Assets written to: ./content/drive/MyDrive/Crayon/Models/VGG16/assets\n",
            "Epoch 20/25\n",
            "142/142 [==============================] - 61s 434ms/step - loss: 0.2365 - acc: 0.9097 - val_loss: 0.4103 - val_acc: 0.8250\n",
            "\n",
            "Epoch 20: val_loss did not improve from 0.20516\n",
            "Epoch 21/25\n",
            "142/142 [==============================] - 62s 438ms/step - loss: 0.2529 - acc: 0.9008 - val_loss: 0.2753 - val_acc: 0.8750\n",
            "\n",
            "Epoch 21: val_loss did not improve from 0.20516\n",
            "Epoch 22/25\n",
            "142/142 [==============================] - 62s 442ms/step - loss: 0.2145 - acc: 0.9150 - val_loss: 0.2995 - val_acc: 0.8750\n",
            "\n",
            "Epoch 22: val_loss did not improve from 0.20516\n",
            "Epoch 23/25\n",
            "142/142 [==============================] - 63s 443ms/step - loss: 0.4666 - acc: 0.8849 - val_loss: 0.2292 - val_acc: 0.9250\n",
            "\n",
            "Epoch 23: val_loss did not improve from 0.20516\n",
            "Epoch 24/25\n",
            "142/142 [==============================] - 63s 446ms/step - loss: 0.2776 - acc: 0.8920 - val_loss: 0.3363 - val_acc: 0.8250\n",
            "\n",
            "Epoch 24: val_loss did not improve from 0.20516\n",
            "Epoch 25/25\n",
            "142/142 [==============================] - 62s 442ms/step - loss: 0.2382 - acc: 0.9013 - val_loss: 0.3359 - val_acc: 0.8750\n",
            "\n",
            "Epoch 25: val_loss did not improve from 0.20516\n"
          ]
        }
      ],
      "source": [
        "train_batch_size = 16\n",
        "val_batch_size = 8\n",
        "steps_per_epoch = train_generator.samples//train_generator.batch_size\n",
        "val_steps = validation_generator.samples//validation_generator.batch_size\n",
        "print(val_steps)\n",
        "\n",
        "\n",
        "resnet_history = base_model.fit(train_generator, validation_data = validation_generator,steps_per_epoch=steps_per_epoch,validation_steps=val_steps ,callbacks=[checkpoint], epochs = 25,class_weight = class_weights,verbose=1)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "hist_df = pd.DataFrame(resnet_history.history) \n",
        "hist_csv_file = 'vgg_16_train_history.csv'\n",
        "with open(hist_csv_file, mode='w') as f:\n",
        "    hist_df.to_csv(f)\n"
      ],
      "metadata": {
        "id": "AaT8AwdIDZ-B"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hqChB6FAAmAm",
        "outputId": "44fd0b3d-4957-4073-d470-aee2f458bbb0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting clodsa\n",
            "  Downloading clodsa-1.2.47.tar.gz (30 kB)\n",
            "Collecting mahotas\n",
            "  Downloading mahotas-1.4.12-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (5.7 MB)\n",
            "\u001b[K     |████████████████████████████████| 5.7 MB 4.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: imutils in /usr/local/lib/python3.7/dist-packages (from clodsa) (0.5.4)\n",
            "Requirement already satisfied: Keras in /usr/local/lib/python3.7/dist-packages (from clodsa) (2.8.0)\n",
            "Collecting commentjson\n",
            "  Downloading commentjson-0.9.0.tar.gz (8.7 kB)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from clodsa) (1.4.1)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from clodsa) (3.1.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from clodsa) (1.21.6)\n",
            "Requirement already satisfied: progressbar2 in /usr/local/lib/python3.7/dist-packages (from clodsa) (3.38.0)\n",
            "Requirement already satisfied: scikit_learn in /usr/local/lib/python3.7/dist-packages (from clodsa) (1.0.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from clodsa) (1.1.0)\n",
            "Collecting lark-parser<0.8.0,>=0.7.1\n",
            "  Downloading lark-parser-0.7.8.tar.gz (276 kB)\n",
            "\u001b[K     |████████████████████████████████| 276 kB 59.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py->clodsa) (1.5.2)\n",
            "Requirement already satisfied: python-utils>=2.3.0 in /usr/local/lib/python3.7/dist-packages (from progressbar2->clodsa) (3.1.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from progressbar2->clodsa) (1.15.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit_learn->clodsa) (3.1.0)\n",
            "Building wheels for collected packages: clodsa, commentjson, lark-parser\n",
            "  Building wheel for clodsa (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for clodsa: filename=clodsa-1.2.47-py2.py3-none-any.whl size=74310 sha256=9f622a1d7bc72edd6ac47acd3184195f5529ce167af553a3fc1e8144d0d97a02\n",
            "  Stored in directory: /root/.cache/pip/wheels/05/ff/0a/0e6e14c2a68d6869a010e979b8fd9d669aaeaa2d8b29de394f\n",
            "  Building wheel for commentjson (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for commentjson: filename=commentjson-0.9.0-py3-none-any.whl size=12092 sha256=3b9a14ff644a49453d86ffbdb7b3e12bfc0d2440b8aa09853e047a837f79e0a0\n",
            "  Stored in directory: /root/.cache/pip/wheels/eb/bb/07/25a7f0718ee3fe137384011b8e56070f91cf950ee6047c287f\n",
            "  Building wheel for lark-parser (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for lark-parser: filename=lark_parser-0.7.8-py2.py3-none-any.whl size=62527 sha256=297e4cef6eb114dea19f164a50ea20f5eb27343b4334ca87eb691e4ed2e7bb5e\n",
            "  Stored in directory: /root/.cache/pip/wheels/92/e3/af/1dc0fdca93232d700ac176af6554cf22b85f3d7e8aeee5ac08\n",
            "Successfully built clodsa commentjson lark-parser\n",
            "Installing collected packages: lark-parser, mahotas, commentjson, clodsa\n",
            "Successfully installed clodsa-1.2.47 commentjson-0.9.0 lark-parser-0.7.8 mahotas-1.4.12\n"
          ]
        }
      ],
      "source": [
        "#apply the augmentation\n",
        "!pip install clodsa\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_VVHccY0UU7b"
      },
      "outputs": [],
      "source": [
        "from matplotlib import pyplot as plt\n",
        "from clodsa.augmentors.augmentorFactory import createAugmentor\n",
        "from clodsa.transformers.transformerFactory import transformerGenerator\n",
        "from clodsa.techniques.techniqueFactory import createTechnique\n",
        "import cv2\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gLqG_EoiUcv0"
      },
      "outputs": [],
      "source": [
        "PROBLEM = \"classification\"\n",
        "ANNOTATION_MODE = \"folders\"\n",
        "INPUT_PATH = \"./temp/Train/\"\n",
        "GENERATION_MODE = \"linear\"\n",
        "OUTPUT_MODE = \"folders\"\n",
        "OUTPUT_PATH= \"./temp/Train/Augment/\"\n",
        "augmentor = createAugmentor(PROBLEM,ANNOTATION_MODE,OUTPUT_MODE,GENERATION_MODE,INPUT_PATH,{\"outputPath\":OUTPUT_PATH})\n",
        "transformer = transformerGenerator(PROBLEM)\n",
        "hFlip = createTechnique(\"flip\",{\"flip\":1})\n",
        "augmentor.addTransformer(transformer(hFlip))\n",
        "crop = createTechnique(\"crop\",{\"percentage\":0.9,\"startFrom\": \"TOPLEFT\"})\n",
        "augmentor.addTransformer(transformer(crop))\n",
        "translation_pos = createTechnique(\"translation\", {\"x\":10,\"y\":10})\n",
        "augmentor.addTransformer(transformer(translation_pos))\n",
        "avgBlur =  createTechnique(\"average_blurring\", {\"kernel\" : 5})\n",
        "augmentor.addTransformer(transformer(avgBlur))\n",
        "equalize = createTechnique(\"equalize_histogram\",{})\n",
        "augmentor.addTransformer(transformer(equalize))\n",
        "salt_and_pepper = createTechnique(\"salt_and_pepper\",{\"low\":0,\"high\":255})\n",
        "augmentor.addTransformer(transformer(salt_and_pepper))\n",
        "none = createTechnique(\"none\",{})\n",
        "augmentor.addTransformer(transformer(none))\n",
        "augmentor.applyAugmentation()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6n5jcyzGaMwj"
      },
      "outputs": [],
      "source": [
        "# !rm -r ./temp/Train/Augment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hdjI7ab7aYBZ",
        "outputId": "dec0c259-0252-4537-dc74-3105c84ae686"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/My Drive/Crayon/temp/Train/Augment\n"
          ]
        }
      ],
      "source": [
        "%cd temp/Train/Augment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QwZkzI5ka37s",
        "outputId": "0cc03c66-14cb-48b0-a22c-c26497443f62"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "covid_n  covid_p\n"
          ]
        }
      ],
      "source": [
        "!ls"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WfxkbEc1991y",
        "outputId": "8f96fd12-1bbe-4181-c2f9-ab32cceca392"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of images in traning covid p folder\n",
            "1785\n",
            "Number of images in traning covid_n folder\n",
            "2\n"
          ]
        }
      ],
      "source": [
        "#Finding the number of images for train test and validation\n",
        "print(\"Number of images in traning covid p folder\")\n",
        "!ls ./covid_p/ | wc -l\n",
        "print(\"Number of images in traning covid_n folder\")\n",
        "!ls ./ | wc -l\n",
        "\n",
        "\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "machine_shape": "hm",
      "name": "Traning _data_aug_Data_Analysis_Sklearn.ipynb",
      "provenance": [],
      "mount_file_id": "10dab2ReLntomQjXw9h6UDZn5dkEVRoc6",
      "authorship_tag": "ABX9TyP+DE4R+nFcNcHCVnszfFfG",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}